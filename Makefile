include Makefile.base.mk

deps:
	pip install -r requirements.txt

build-local:
	chmod +x container/$(DEPLOYMENT_NAME)/train
	chmod +x container/$(DEPLOYMENT_NAME)/serve
	docker build -t $(DEPLOYMENT_NAME):$(BUILD_ID) container --build-arg IMAGE=$(DEPLOYMENT_NAME)
	docker tag $(DEPLOYMENT_NAME):$(BUILD_ID) $(DEPLOYMENT_NAME):latest


train-local:
	mkdir -p $(shell pwd)/container/local_test/test_dir/model
	mkdir -p $(shell pwd)/container/local_test/test_dir/output
	rm -rf $(shell pwd)/container/local_test/test_dir/model/*
	rm -rf $(shell pwd)/container/local_test/test_dir/output/*
	docker run -v $(shell pwd)/container/local_test/test_dir:/opt/ml --rm $(DEPLOYMENT_NAME) train

serve-local:
	docker run -v $(shell pwd)/container/local_test/test_dir:/opt/ml -p 8080:8080 --rm $(DEPLOYMENT_NAME) serve

predict-local:
	bash $(shell pwd)/container/local_test/predict.sh $(shell pwd)/container/local_test/payload.json

get-s3-data:
	aws s3 cp  s3://hs-machine-learning-processed-production/inbound-autotag/data/ \
	$(shell pwd)/container/local_test/test_dir/input/data/training/ --recursive --profile ml-prod

test:
	@echo "Not implemented."

# Path to checkpoint file or a directory containing checkpoint files. Passing
# a directory will only work if there is also a file named 'checkpoint' which
# lists the available checkpoints in the directory. It will not work if you
# point to a directory with just a copy of a model checkpoint: in that case,
# you will need to pass the checkpoint path explicitly.
CHECKPOINT_PATH := "${HOME}/projects/im2txt/im2txt/model/train/"
# Vocabulary file generated by the preprocessing script.
VOCAB_FILE := "${HOME}/projects/im2txt/im2txt/data/mscoco/word_counts.txt"

# JPEG image file to caption.
IMAGE_FILE := "${HOME}/projects/im2txt/im2txt/data/mscoco/raw-data/val2014/coffee.jpg"

# Ignore GPU devices (only necessary if your GPU is currently memory
# constrained, for example, by running the training script).
export CUDA_VISIBLE_DEVICES=""

build:
	# Build the inference binary.
	bazel build -c opt //im2txt:run_inference

test:
	# Run inference to generate captions.
	bazel-bin/im2txt/run_inference \
	  --checkpoint_path=${CHECKPOINT_PATH} \
	  --vocab_file=${VOCAB_FILE} \
	  --input_files=${IMAGE_FILE}